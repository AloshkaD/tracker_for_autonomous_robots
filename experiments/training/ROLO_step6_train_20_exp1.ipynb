{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright (c) <2016> <GUANGHAN NING>. All Rights Reserved.\n",
    " \n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License. \n",
    "\n",
    "'''\n",
    "Script File: ROLO_step6_train_20_exp1.py\n",
    "\n",
    "Description:\n",
    "\n",
    "\tROLO is short for Recurrent YOLO, aimed at simultaneous object detection and tracking\n",
    "\tPaper: http://arxiv.org/abs/1607.05781\n",
    "\tAuthor: Guanghan Ning\n",
    "\tWebpage: http://guanghan.info/\n",
    "'''\n",
    "\n",
    "# Imports\n",
    "import sys, os\n",
    "path_to_utils = '/home/a/SDC/defence/ROLO/utils'\n",
    "sys.path.extend([path_to_utils])\n",
    "import ROLO_utils as utils\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow.models.rnn import rnn, rnn_cell\n",
    "from tensorflow.contrib import rnn\n",
    "#from tensorflow.python.ops.nn import rnn_cell\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import os.path\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLO init\n",
      "Utils init\n",
      "self.cfgPath=\n",
      "TRAINING ROLO...\n",
      "name lstm_test\n",
      "_X Tensor(\"Placeholder:0\", shape=(?, 6, 4102), dtype=float32)\n",
      "_istate Tensor(\"Placeholder_1:0\", shape=(?, 8204), dtype=float32)\n",
      "_weights {'out': <contextlib._GeneratorContextManager object at 0x7f32c3a4a898>}\n",
      "_biases {'out': <contextlib._GeneratorContextManager object at 0x7f32c3a4a358>}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not iterable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ace8a94ec52f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-ace8a94ec52f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argvs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;34m'''----------------------------------------main-----------------------------------------------------'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mROLO_TF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ace8a94ec52f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, argvs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROLO init\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ace8a94ec52f>\u001b[0m in \u001b[0;36mROLO\u001b[0;34m(self, argvs)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_in_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_20\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;34m'''----------------------------------------main-----------------------------------------------------'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ace8a94ec52f>\u001b[0m in \u001b[0;36mtrain_20\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TRAINING ROLO...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mlog_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/trainging-20-log.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#open in append mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;34m''' TUNE THIS'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ace8a94ec52f>\u001b[0m in \u001b[0;36mbuild_networks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# Build rolo layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm_test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mistate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;31m#self.ious= tf.Variable(tf.zeros([self.batch_size]), name=\"ious\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mious\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ace8a94ec52f>\u001b[0m in \u001b[0;36mLSTM_single\u001b[0;34m(self, name, _X, _istate, _weights, _biases)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m#outputs, state = tf.nn.rnn(cell, [_X[step]], state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_X\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;31m#if step == 0:    = state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\u001b[0m in \u001b[0;36mstatic_rnn\u001b[0;34m(cell, inputs, initial_state, dtype, sequence_length, scope)\u001b[0m\n\u001b[1;32m    195\u001b[0m             state_size=cell.state_size)\n\u001b[1;32m    196\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvarscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0;31m# pylint: disable=cell-var-from-loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m       \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m       \u001b[0;31m# pylint: enable=cell-var-from-loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_is_tuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0mc_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_prev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m       \u001b[0mc_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0minvoked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \"\"\"\n\u001b[0;32m--> 504\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'Tensor' object is not iterable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not iterable."
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "class ROLO_TF:\n",
    "    disp_console = False\n",
    "    restore_weights = True#False\n",
    "\n",
    "    # YOLO parameters\n",
    "    fromfile = None\n",
    "    tofile_img = 'test/output.jpg'\n",
    "    tofile_txt = 'test/output.txt'\n",
    "    imshow = True\n",
    "    filewrite_img = False\n",
    "    filewrite_txt = False\n",
    "    yolo_weights_file = '/home/a/SDC/defence/weights/YOLO_small.ckpt'\n",
    "    alpha = 0.1\n",
    "    threshold = 0.2\n",
    "    iou_threshold = 0.5\n",
    "    num_class = 20\n",
    "    num_box = 2\n",
    "    grid_size = 7\n",
    "    classes =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]\n",
    "    w_img, h_img = [352, 240]\n",
    "\n",
    "    # ROLO Network Parameters\n",
    "    rolo_weights_file = '/home/a/SDC/defence/weights/model_step6_exp1.ckpt' \n",
    "    lstm_depth = 3\n",
    "    num_steps = 6  # number of frames as an input sequence\n",
    "    num_feat = 4096\n",
    "    num_predict = 6 # final output of LSTM 6 loc parameters\n",
    "    num_gt = 4\n",
    "    num_input = num_feat + num_predict # data input: 4096+6= 5002\n",
    "\n",
    "    # ROLO Training Parameters\n",
    "    #learning_rate = 0.00001 #training\n",
    "    learning_rate = 0.00001 #testing\n",
    "\n",
    "    training_iters = 210#100000\n",
    "    batch_size = 1 #128\n",
    "    display_step = 1\n",
    "\n",
    "    # tf Graph input\n",
    "    x = tf.placeholder(\"float32\", [None, num_steps, num_input])\n",
    "    istate = tf.placeholder(\"float32\", [None, 2*num_input]) #state & cell => 2x num_input\n",
    "    y = tf.placeholder(\"float32\", [None, num_gt])\n",
    "\n",
    "    # Define weights\n",
    "    weights = {\n",
    "        'out': tf.variable_scope(tf.random_normal([num_input, num_predict]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.variable_scope(tf.random_normal([num_predict]))\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__(self,argvs = []):\n",
    "        print(\"ROLO init\")\n",
    "        self.ROLO(argvs)\n",
    "\n",
    "\n",
    "    def LSTM_single(self, name,  _X, _istate, _weights, _biases):\n",
    "        #with tf.device('/gpu:0'):\n",
    "            # input shape: (batch_size, n_steps, n_input)\n",
    "        print('name',name)\n",
    "        print('_X',_X)\n",
    "        print('_istate',_istate)\n",
    "        print('_weights',_weights)\n",
    "        print('_biases',_biases)\n",
    "        _X = tf.transpose(_X, [1, 0, 2])  # permute num_steps and batch_size\n",
    "            # Reshape to prepare input to hidden activation\n",
    "        _X = tf.reshape(_X, [self.num_steps * self.batch_size, self.num_input]) # (num_steps*batch_size, num_input)\n",
    "            # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "            #_X = tf.split(0, self.num_steps, _X) # n_steps * (batch_size, num_input)\n",
    "        _X = tf.split(_X, self.num_steps , 0) # n_steps * (batch_size, num_input)\n",
    "            \n",
    "        #cell = tf.nn.rnn_cell.LSTMCell(self.num_input, self.num_input)\n",
    "        cell = tf.contrib.rnn.LSTMCell(self.num_input, state_is_tuple=True)\n",
    "        #cell = tf.contrib.rnn.LSTMCell(self.num_input)\n",
    "        #print(_X.shape)\n",
    "        state = _istate\n",
    "\n",
    "       \n",
    "        for step in range(self.num_steps):\n",
    "            #outputs, state = tf.nn.rnn(cell, [_X[step]], state)\n",
    "            outputs, state = tf.contrib.rnn.static_rnn(cell, [_X [step] ], state, dtype=tf.float32)\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            #if step == 0:    = state\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    # Experiment with dropout\n",
    "    def dropout_features(self, feature, prob):\n",
    "        num_drop = int(prob * 4096)\n",
    "        drop_index = random.sample(xrange(4096), num_drop)\n",
    "        for i in range(len(drop_index)):\n",
    "            index = drop_index[i]\n",
    "            feature[index] = 0\n",
    "        return feature\n",
    "\n",
    "\n",
    "    '''---------------------------------------------------------------------------------------'''\n",
    "    def build_networks(self):\n",
    "        if self.disp_console : print (\"Building ROLO graph...\")\n",
    "\n",
    "        # Build rolo layers\n",
    "        self.lstm_module = self.LSTM_single('lstm_test', self.x, self.istate, self.weights, self.biases)\n",
    "        #self.ious= tf.Variable(tf.zeros([self.batch_size]), name=\"ious\")\n",
    "        self.ious= tf.variable_scope(tf.zeros([self.batch_size]))\n",
    "        self.sess = tf.Session()\n",
    "        #self.sess.run(tf.initialize_all_variables())\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.saver = tf.train.Saver()\n",
    "        #self.saver.restore(self.sess, self.rolo_weights_file)\n",
    "        if self.disp_console : print (\"Loading complete!\" + '\\n')\n",
    "\n",
    "\n",
    "    def training(self, x_path, y_path):\n",
    "        total_loss = 0\n",
    "\n",
    "        if self.disp_console: print(\"TRAINING ROLO...\")\n",
    "        # Use rolo_input for LSTM training\n",
    "        print('self.x',self.x)\n",
    "        print('self.istate',self.istate)\n",
    "        print('self.weights',self.weights)\n",
    "        print('self.biases',self.biases)\n",
    "\n",
    "        pred = self.LSTM_single('lstm_train', self.x, self.istate, self.weights, self.biases)\n",
    "        if self.disp_console: print(\"pred: \", pred)\n",
    "        self.pred_location = pred[0][:, 4097:4101]\n",
    "        if self.disp_console: print(\"pred_location: \", self.pred_location)\n",
    "        if self.disp_console: print(\"self.y: \", self.y)\n",
    "\n",
    "        self.correct_prediction = tf.square(self.pred_location - self.y)\n",
    "        if self.disp_console: print(\"self.correct_prediction: \", self.correct_prediction)\n",
    "        self.accuracy = tf.reduce_mean(self.correct_prediction) * 100\n",
    "        if self.disp_console: print(\"self.accuracy: \", self.accuracy)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.accuracy) # Adam Optimizer\n",
    "\n",
    "        # Initializing the variables\n",
    "        #init = tf.initialize_all_variables()\n",
    "        init = tf.global_variables_initializer()\n",
    "        # Launch the graph\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            if (self.restore_weights == True):\n",
    "                sess.run(init)\n",
    "                self.saver.restore(sess, self.rolo_weights_file)\n",
    "                print (\"Loading complete!\" + '\\n')\n",
    "            else:\n",
    "                sess.run(init)\n",
    "\n",
    "            id = 0\n",
    "\n",
    "            # Keep training until reach max iterations\n",
    "            while id * self.batch_size < self.training_iters:\n",
    "                # Load training data & ground truth\n",
    "                batch_xs = self.rolo_utils.load_yolo_output(x_path, self.batch_size, self.num_steps, id) # [num_of_examples, num_input] (depth == 1)\n",
    "                print('len(batch_xs)= ', len(batch_xs))\n",
    "                # for item in range(len(batch_xs)):\n",
    "\n",
    "                batch_ys = self.rolo_utils.load_rolo_gt(y_path, self.batch_size, self.num_steps, id)\n",
    "                batch_ys = self.locations_from_0_to_1(self.w_img, self.h_img, batch_ys)\n",
    "\n",
    "                # Reshape data to get 3 seq of 5002 elements\n",
    "                batch_xs = np.reshape(batch_xs, [self.batch_size, self.num_steps, self.num_input])\n",
    "                batch_ys = np.reshape(batch_ys, [self.batch_size, 4])\n",
    "                if self.disp_console: print(\"Batch_ys: \", batch_ys)\n",
    "\n",
    "                pred_location= sess.run(self.pred_location,feed_dict={self.x: batch_xs, self.y: batch_ys, self.istate: np.zeros((self.batch_size, 2*self.num_input))})\n",
    "                if self.disp_console: print(\"ROLO Pred: \", pred_location)\n",
    "                #print(\"len(pred) = \", len(pred_location))\n",
    "                if self.disp_console: print(\"ROLO Pred in pixel: \", pred_location[0][0]*self.w_img, pred_location[0][1]*self.h_img, pred_location[0][2]*self.w_img, pred_location[0][3]*self.h_img)\n",
    "                #print(\"correct_prediction int: \", (pred_location + 0.1).astype(int))\n",
    "\n",
    "                # Save pred_location to file\n",
    "                utils.save_rolo_output(self.output_path, pred_location, id, self.num_steps, self.batch_size)\n",
    "\n",
    "                sess.run(optimizer, feed_dict={self.x: batch_xs, self.y: batch_ys, self.istate: np.zeros((self.batch_size, 2*self.num_input))})\n",
    "                if id % self.display_step == 0:\n",
    "                    # Calculate batch loss\n",
    "                    loss = sess.run(self.accuracy, feed_dict={self.x: batch_xs, self.y: batch_ys, self.istate: np.zeros((self.batch_size, 2*self.num_input))})\n",
    "                    if self.disp_console: print (\"Iter \" + str(id*self.batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) )#+ \"{:.5f}\".format(self.accuracy)\n",
    "                    total_loss += loss\n",
    "                id += 1\n",
    "                if self.disp_console: print(id)\n",
    "\n",
    "                # show 3 kinds of locations, compare!\n",
    "\n",
    "            print (\"Optimization Finished!\")\n",
    "            avg_loss = total_loss/id\n",
    "            print (\"Avg loss: \" + str(avg_loss))\n",
    "            save_path = self.saver.save(sess, self.rolo_weights_file)\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "        return avg_loss\n",
    "\n",
    "\n",
    "    def train_20(self):\n",
    "        print(\"TRAINING ROLO...\")\n",
    "        log_file = open(\"output/trainging-20-log.txt\", \"a\") #open in append mode\n",
    "        self.build_networks()\n",
    "\n",
    "        ''' TUNE THIS'''\n",
    "        num_videos = 20\n",
    "        epoches = 20 * 100\n",
    "\n",
    "        # Use rolo_input for LSTM training\n",
    "        pred = self.LSTM_single('lstm_train', self.x, self.istate, self.weights, self.biases)\n",
    "        self.pred_location = pred[0][:, 4097:4101]\n",
    "        self.correct_prediction = tf.square(self.pred_location - self.y)\n",
    "        self.accuracy = tf.reduce_mean(self.correct_prediction) * 100\n",
    "        self.learning_rate = 0.00001\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.accuracy) # Adam Optimizer\n",
    "\n",
    "        # Initializing the variables\n",
    "        #init = tf.initialize_all_variables()\n",
    "        init = tf.global_variables_initializer()\n",
    "        # Launch the graph\n",
    "        with tf.Session() as sess:\n",
    "            if (self.restore_weights == True):\n",
    "                sess.run(init)\n",
    "                self.saver.restore(sess, self.rolo_weights_file)\n",
    "                print (\"Loading complete!\" + '\\n')\n",
    "            else:\n",
    "                sess.run(init)\n",
    "\n",
    "            for epoch in range(epoches):\n",
    "                i = epoch % num_videos\n",
    "                [self.w_img, self.h_img, sequence_name, dummy, self.training_iters]= utils.choose_video_sequence(i)\n",
    "\n",
    "                x_path = os.path.join('benchmark/DATA', sequence_name, 'yolo_out/')\n",
    "                y_path = os.path.join('benchmark/DATA', sequence_name, 'groundtruth_rect.txt')\n",
    "                self.output_path = os.path.join('benchmark/DATA', sequence_name, 'rolo_out_train/')\n",
    "                utils.createFolder(self.output_path)\n",
    "                total_loss = 0\n",
    "                id = 0\n",
    "\n",
    "                # Keep training until reach max iterations\n",
    "                while id  < self.training_iters- self.num_steps:\n",
    "                    # Load training data & ground truth\n",
    "                    batch_xs = self.rolo_utils.load_yolo_output_test(x_path, self.batch_size, self.num_steps, id) # [num_of_examples, num_input] (depth == 1)\n",
    "\n",
    "                    # Apply dropout to batch_xs\n",
    "                    #for item in range(len(batch_xs)):\n",
    "                    #    batch_xs[item] = self.dropout_features(batch_xs[item], 0.4)\n",
    "\n",
    "                    #print(id)\n",
    "                    batch_ys = self.rolo_utils.load_rolo_gt_test(y_path, self.batch_size, self.num_steps, id)\n",
    "                    batch_ys = utils.locations_from_0_to_1(self.w_img, self.h_img, batch_ys)\n",
    "\n",
    "                    # Reshape data to get 3 seq of 5002 elements\n",
    "                    batch_xs = np.reshape(batch_xs, [self.batch_size, self.num_steps, self.num_input])\n",
    "                    batch_ys = np.reshape(batch_ys, [self.batch_size, 4])\n",
    "                    if self.disp_console: print(\"Batch_ys: \", batch_ys)\n",
    "\n",
    "                    pred_location= sess.run(self.pred_location,feed_dict={self.x: batch_xs, self.y: batch_ys, self.istate: np.zeros((self.batch_size, 2*self.num_input))})\n",
    "                    if self.disp_console: print(\"ROLO Pred: \", pred_location)\n",
    "                    #print(\"len(pred) = \", len(pred_location))\n",
    "                    if self.disp_console: print(\"ROLO Pred in pixel: \", pred_location[0][0]*self.w_img, pred_location[0][1]*self.h_img, pred_location[0][2]*self.w_img, pred_location[0][3]*self.h_img)\n",
    "                    #print(\"correct_prediction int: \", (pred_location + 0.1).astype(int))\n",
    "\n",
    "                    # Save pred_location to file\n",
    "                    utils.save_rolo_output(self.output_path, pred_location, id, self.num_steps, self.batch_size)\n",
    "\n",
    "                    sess.run(self.optimizer, feed_dict={self.x: batch_xs, self.y: batch_ys, self.istate: np.zeros((self.batch_size, 2*self.num_input))})\n",
    "                    if id % self.display_step == 0:\n",
    "                        # Calculate batch loss\n",
    "                        loss = sess.run(self.accuracy, feed_dict={self.x: batch_xs, self.y: batch_ys, self.istate: np.zeros((self.batch_size, 2*self.num_input))})\n",
    "                        if self.disp_console: print (\"Iter \" + str(id*self.batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss)) #+ \"{:.5f}\".format(self.accuracy)\n",
    "                        total_loss += loss\n",
    "                    id += 1\n",
    "                    if self.disp_console: print(id)\n",
    "\n",
    "                #print \"Optimization Finished!\"\n",
    "                avg_loss = total_loss/id\n",
    "                print (\"Avg loss: \" + sequence_name + \": \" + str(avg_loss))\n",
    "\n",
    "                log_file.write(str(\"{:.3f}\".format(avg_loss)) + '  ')\n",
    "                if i+1==num_videos:\n",
    "                    log_file.write('\\n')\n",
    "                    save_path = self.saver.save(sess, self.rolo_weights_file)\n",
    "                    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "        log_file.close()\n",
    "        return\n",
    "\n",
    "\n",
    "    def ROLO(self, argvs):\n",
    "\n",
    "            self.rolo_utils= utils.ROLO_utils()\n",
    "            self.rolo_utils.loadCfg()\n",
    "            self.params = self.rolo_utils.params\n",
    "\n",
    "            arguments = self.rolo_utils.argv_parser(argvs)\n",
    "\n",
    "            if self.rolo_utils.flag_train is True:\n",
    "                self.training(utils.x_path, utils.y_path)\n",
    "            elif self.rolo_utils.flag_track is True:\n",
    "                self.build_networks()\n",
    "                self.track_from_file(utils.file_in_path)\n",
    "            elif self.rolo_utils.flag_detect is True:\n",
    "                self.build_networks()\n",
    "                self.detect_from_file(utils.file_in_path)\n",
    "            else:\n",
    "                self.train_20()\n",
    "\n",
    "    '''----------------------------------------main-----------------------------------------------------'''\n",
    "def main(argvs):\n",
    "        ROLO_TF(argvs)\n",
    "\n",
    "if __name__=='__main__':\n",
    "        main(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
